{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bdbdd5-5d2e-4ca7-a369-2b5686d1e418",
   "metadata": {},
   "source": [
    "# <center>Assigments 11</center>  https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969236f4-f10a-4250-8e41-529ed82aadc2",
   "metadata": {},
   "source": [
    "## Using a pre-trained Imagenet network to predict images into one of the 1000 Imagenet classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8830bf-addb-4204-bd0a-a19148bffe05",
   "metadata": {},
   "source": [
    "Fast.ai‘s Imagenette Dataset\r\n",
    "Imagenette is a dataset that’s extracted from the large ImageNet collection of images. The reason behind releasing Imagenette is that researchers and students can practice on ImageNet-level images without needing that many computing resources.g:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b5148-bf57-4561-8c3d-5c2f2a0f10fb",
   "metadata": {},
   "source": [
    "### Step 1: Download the Imagenette dataset\n",
    "### Step 2: Load images using ImageDataGenerator\n",
    "### Step 3: Build a basic CNN model for image classification\n",
    "### Step 4: Use transfer learning (VGG16) to improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01972bf-fa92-4acc-9863-ccdf8b82e201",
   "metadata": {},
   "source": [
    "## Step 1: Download the Imagenette dataset\n",
    "## https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440cf03-6d5b-4348-85f4-99f68487c6b9",
   "metadata": {},
   "source": [
    "## Step 1: Download the Imagenette dataset\n",
    "## https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fe7f1-820d-4af1-ac58-1ebd3d5cfe8b",
   "metadata": {},
   "source": [
    "## Step 2: Load images using ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cebaca-49a9-4c32-a7ae-cde5b968c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c8866d-594b-4fac-982a-371b0d488b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "Found 3927 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a new generator\n",
    "imagegen = ImageDataGenerator()\n",
    "# load train data\n",
    "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "# load val data\n",
    "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0c4a78-40f8-4fb3-93cf-050d1fa92c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = VGG16(include_top=False, weights='imagenet') \n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec1d03-8bd0-432c-a29f-42e2a8eb957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/74 [==================>...........] - ETA: 12:41"
     ]
    }
   ],
   "source": [
    "vgg_features_train = pretrained_model.predict(train) \n",
    "vgg_features_val = pretrained_model.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad8643-5eb5-4ef5-881b-0713c0de304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = to_categorical(train.labels) \n",
    "val_target = to_categorical(val.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48c784-84d5-4269-95dd-9598b4852c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(7,7,512)))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# train model using features generated from VGG16 model\n",
    "model2.fit(vgg_features_train, train_target, epochs=50, batch_size=128, validation_data=(vgg_features_val, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2186fb9-9448-4076-b410-aa226a75cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy graph                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba00a25-3a7e-45cd-a812-33d702dd9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create an ImageDataGenerator for loading and preprocessing images\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "# Load a batch of images from the dataset\n",
    "batch_size = 10  # Number of images you want to load for prediction\n",
    "sample_generator = datagen.flow_from_directory(\"imagenette2/val/\", class_mode=None, shuffle=True, batch_size=batch_size, target_size=(224, 224))\n",
    "\n",
    "# Get a batch of images and preprocess them\n",
    "sample_images = next(sample_generator)\n",
    "sample_images_features = pretrained_model.predict(sample_images)\n",
    "\n",
    "# Predict using the model\n",
    "predictions = model2.predict(sample_images_features)\n",
    "\n",
    "# Get class labels for the predictions\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map class indices to class labels\n",
    "class_labels = { \n",
    "    0: \"tench\",\n",
    "    1: \"springer\",\n",
    "    2: \"casette_player\",\n",
    "    3: \"chain_saw\",\n",
    "    4: \"church\",\n",
    "    5: \"French_horn\",\n",
    "    6: \"garbage_truck\",\n",
    "    7: \"gas_pump\",\n",
    "    8: \"golf_ball\",\n",
    "    9: \"parachute\"\n",
    "}\n",
    "predicted_labels = [class_labels[index] for index in predicted_classes]\n",
    "\n",
    "# Display the predicted class labels for the sample images\n",
    "for i in range(batch_size):\n",
    "    print(\"Predicted class label for sample image\", i, \":\", predicted_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe898da8-f9d3-45c5-b079-8ba786ee34b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
